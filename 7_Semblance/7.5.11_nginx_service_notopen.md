 kubectl exec -it frontend-deployment-58868f5d95-8grbb  -- curl http://backend-service:8080

@rifaterdemsahin ➜ /workspaces/PolicyManagement/Symbols/Nginx (main) $ kubectl exec -it frontend-deployment-58868f5d95-8grbb  -- curl http://backend-service:8080
curl: (7) Failed to connect to backend-service port 8080 after 0 ms: Couldn't connect to server
command terminated with exit code 7

See 'kubectl exec -h' for help and examples
@rifaterdemsahin ➜ /workspaces/PolicyManagement/Symbols/Nginx (main) $ kubectl exec -it frontend-deployment-58868f5d95-8grbb -- ls
bin  boot  dev  docker-entrypoint.d  docker-entrypoint.sh  etc  home  lib  lib64  media  mnt  opt  proc  root  run  sbin  srv  sys  tmp  usr  var
@rifaterdemsahin ➜ /workspaces/PolicyManagement/Symbols/Nginx (main) $ kubectl exec -it frontend-deployment-58868f5d95-8grbb  -- curl http://backend-service:8080
curl: (7) Failed to connect to backend-service port 8080 after 0 ms: Couldn't connect to server
command terminated with exit code 7
@rifaterdemsahin ➜ /workspaces/PolicyManagement/Symbols/Nginx (main) $ 


The error message you’re seeing, `curl: (7) Failed to connect to backend-service port 8080`, indicates that the `frontend-deployment` Pod is unable to connect to the `backend-service` on port 8080. Here are a few things to check and troubleshoot:

1. **Service Name and Port**:
   - Verify that `backend-service` is the correct name of the service. Run `kubectl get svc` to list all services in the namespace and confirm the name and port.
   - Check if `backend-service` is exposed on port 8080 by inspecting it with:
     ```sh
     kubectl get svc backend-service -o yaml
     ```

@rifaterdemsahin ➜ /workspaces/PolicyManagement/Symbols/Nginx (main) $ kubectl get svc backend-service -o yaml
apiVersion: v1
kind: Service
metadata:
  annotations:
    kubectl.kubernetes.io/last-applied-configuration: |
      {"apiVersion":"v1","kind":"Service","metadata":{"annotations":{},"name":"backend-service","namespace":"default"},"spec":{"ports":[{"port":8080,"protocol":"TCP","targetPort":8080}],"selector":{"app":"backend"},"type":"ClusterIP"}}
  creationTimestamp: "2024-11-08T10:34:59Z"
  name: backend-service
  namespace: default
  resourceVersion: "477"
  uid: 8cf1d5b6-4e56-41ea-b8ee-d9b4eb6d2a68
spec:
  clusterIP: 10.100.238.152
  clusterIPs:
  - 10.100.238.152
  internalTrafficPolicy: Cluster
  ipFamilies:
  - IPv4
  ipFamilyPolicy: SingleStack
  ports:
  - port: 8080
    protocol: TCP
    targetPort: 8080
  selector:
    app: backend
  sessionAffinity: None
  type: ClusterIP
status:
  loadBalancer: {}


2. **Namespace**:
   - Ensure that both `frontend-deployment` and `backend-service` are in the same namespace. If they are in different namespaces, you will need to include the namespace in the service URL (e.g., `http://backend-service.namespace:8080`).
   - You can verify namespaces by running:
     ```sh
     kubectl get pods --all-namespaces
     ```

rifaterdemsahin ➜ /workspaces/PolicyManagement/Symbols/Nginx (main) $ kubectl get pods --all-namespaces
NAMESPACE     NAME                                   READY   STATUS    RESTARTS   AGE
default       backend-deployment-76f6887dd9-c5s8q    1/1     Running   0          7m43s
default       frontend-deployment-58868f5d95-8grbb   1/1     Running   0          7m28s
kube-system   coredns-6f6b679f8f-wd69b               1/1     Running   0          9m24s
kube-system   etcd-minikube                          1/1     Running   0          9m31s
kube-system   kube-apiserver-minikube                1/1     Running   0          9m31s
kube-system   kube-controller-manager-minikube       1/1     Running   0          9m29s
kube-system   kube-proxy-7zxdh                       1/1     Running   0          9m24s
kube-system   kube-scheduler-minikube                1/1     Running   0          9m30s
kube-system   storage-provisioner                    1/1     Running   0          9m27s
@rifaterdemsahin ➜ /workspaces/PolicyManagement/Symbols/Nginx (main) $ 

3. **Network Policies**:
   - If network policies are enabled, they might be blocking communication between the frontend and backend Pods. Check if there are any network policies in place that might prevent access to `backend-service`.
   - You can inspect network policies with:
     ```sh
     kubectl get networkpolicy -A
     ```

     @rifaterdemsahin ➜ /workspaces/PolicyManagement/Symbols/Nginx (main) $ kubectl get networkpolicy -A
No resources found

4. **Backend Pod Status**:
   - Verify that the backend Pods are running and ready. If they are not, there could be issues with the backend deployment itself.
   - Check the status of the backend Pods with:
     ```sh
     kubectl get pods -l app=backend
     ```

@rifaterdemsahin ➜ /workspaces/PolicyManagement/Symbols/Nginx (main) $    kubectl get pods -l app=backend
NAME                                  READY   STATUS    RESTARTS   AGE
backend-deployment-76f6887dd9-c5s8q   1/1     Running   0          8m42s


5. **Logs for Backend Pods**:
   - Check the logs of the backend Pods for any errors. This can help identify issues related to readiness, port configuration, or startup errors.
   - Use the following command to get the logs:
     ```sh
     kubectl logs <backend-pod-name>
       kubectl logs backend-deployment-76f6887dd9-c5s8q 
     ```
@rifaterdemsahin ➜ /workspaces/PolicyManagement/Symbols/Nginx (main) $ kubectl logs backend-deployment-76f6887dd9-c5s8q
/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2024/11/08 10:35:00 [notice] 1#1: using the "epoll" event method
2024/11/08 10:35:00 [notice] 1#1: nginx/1.27.2
2024/11/08 10:35:00 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) 
2024/11/08 10:35:00 [notice] 1#1: OS: Linux 6.5.0-1025-azure
2024/11/08 10:35:00 [notice] 1#1: getrlimit(RLIMIT_NOFILE): 1048576:1048576
2024/11/08 10:35:00 [notice] 1#1: start worker processes
2024/11/08 10:35:00 [notice] 1#1: start worker process 29
2024/11/08 10:35:00 [notice] 1#1: start worker process 30
@rifaterdemsahin ➜ /workspaces/PolicyManagement/Symbols/Nginx (main) $ 



6. **Cluster DNS**:
   - Verify that DNS is working correctly within your cluster. You can test DNS resolution for `backend-service` by running this command within the frontend Pod:
     ```sh
     kubectl exec -it frontend-deployment-58868f5d95-8grbb -- nslookup backend-service
     ```

     @rifaterdemsahin ➜ /workspaces/PolicyManagement/Symbols/Nginx (main) $ kubectl exec -it frontend-deployment-58868f5d95-8grbb -- nslookup backend-service
E1108 10:44:50.297306   30887 websocket.go:296] Unknown stream id 1, discarding message
                                                                                       OCI runtime exec failed: exec failed: unable to start container process: exec: "nslookup": executable file not found in $PATH: unknown
command terminated with exit code 126

By following these steps, you should be able to identify the root cause of the connectivity issue between your frontend and backend services. Let me know if any errors arise during these checks!

=================>>>>>>>>>>>>>>>>>>>>>>>>>=================

It appears that the `frontend-deployment` Pod cannot connect to `backend-service` on port 8080. Based on your diagnostic steps and findings so far, here are additional checks and steps to troubleshoot further:

### Additional Troubleshooting Steps

1. **Verify Target Port Configuration on Backend Service**
   - Make sure that the backend service is indeed listening on port 8080 within the backend container. You can check this by running:
     ```sh
     kubectl exec -it <backend-pod-name> -- netstat -tuln | grep 8080
     kubectl exec -it backend-deployment-76f6887dd9-c5s8q -- netstat -tuln | grep 8080
     
     backend-deployment-76f6887dd9-c5s8q 
     ```
   - If nothing is returned, it means the backend container might not be exposing port 8080, and you may need to update the container configuration.

@rifaterdemsahin ➜ /workspaces/PolicyManagement/Symbols/Nginx (main) $ kubectl exec -it backend-deployment-76f6887dd9-c5s8q -- netstat -tuln | grep 8080
command terminated with exit code 126
@rifaterdemsahin ➜ /workspaces/PolicyManagement/Symbols/Nginx (main) $ 

2. **Check Service Connectivity with `nslookup`**
   - To ensure that DNS resolution within your cluster is functioning correctly, try an `nslookup` for `backend-service` from the frontend Pod:
     ```sh
     kubectl exec -it frontend-deployment-58868f5d95-8grbb -- nslookup backend-service
     ```
   - This should return the ClusterIP assigned to `backend-service`. If it doesn’t, there may be an issue with DNS configuration in your cluster.

3. **Check Firewall or Security Settings (Network Policies)**
   - Even though you confirmed no network policies are set, check if there are any other firewall settings at the Kubernetes or network layer that could be blocking communication between these Pods.

4. **Confirm Service Endpoint**
   - Check if `backend-service` has endpoints that point to the backend Pod. If there are no endpoints, the service may not be linked to the Pod correctly:
     ```sh
     kubectl get endpoints backend-service
     ```
   - If the endpoints are empty, try redeploying `backend-service` to reset connections, or ensure the `backend` selector in the service configuration is accurate.

5. **Inspect Pod-Level Configuration for Application Logs**
   - If all configuration seems correct but connectivity is still an issue, you may need to check if the backend application is correctly starting up and binding to port 8080. Confirm by checking logs within the backend Pod.

After performing these checks, you should have a clearer idea of the source of the connectivity issue.